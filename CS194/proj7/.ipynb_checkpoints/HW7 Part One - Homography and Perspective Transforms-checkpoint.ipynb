{
 "metadata": {
  "name": "",
  "signature": "sha256:9e9ad808c9319de40fa05aa7886c98f787636693568387040535e71600fb3e6d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import os\n",
      "import scipy\n",
      "import skimage\n",
      "import skimage.io as skio\n",
      "\n",
      "from math import floor, sqrt\n",
      "from Queue import PriorityQueue\n",
      "from scipy.interpolate import RectBivariateSpline\n",
      "from scipy.interpolate import interp2d\n",
      "from scipy.ndimage.filters import convolve\n",
      "from scipy.misc import imresize\n",
      "from scipy.stats import multivariate_normal\n",
      "from skimage.color import rgb2gray\n",
      "from skimage.draw import polygon\n",
      "from skimage.feature import corner_harris, peak_local_max"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define functions for homography matrix computation and transformation\n",
      "def get_points(img):\n",
      "    plt.imshow(img)\n",
      "    points = plt.ginput(n=0, timeout=0)\n",
      "    plt.close()\n",
      "    return points\n",
      "\n",
      "def computeH(im1_pts, im2_pts):\n",
      "    # Compute the homography matrix between im1_pts and im2_pts\n",
      "    A = np.zeros((2*len(im1_pts), 8))\n",
      "    b = np.zeros(2*len(im2_pts))\n",
      "    for i in range(len(im1_pts)):\n",
      "        x_i, y_i = im1_pts[i]\n",
      "        u_i, v_i = im2_pts[i]\n",
      "        curr_row = np.array([[x_i, y_i, 1,   0,   0, 0, -u_i*x_i, -u_i*y_i],\n",
      "                             [  0,   0, 0, x_i, y_i, 1, -v_i*x_i, -v_i*y_i]])\n",
      "        A[2*i:2*(i+1), :] = curr_row\n",
      "        b[2*i] = u_i\n",
      "        b[2*i + 1] = v_i\n",
      "    # After loading in points, get H by least squares\n",
      "    try:\n",
      "        H = np.linalg.inv(A.T.dot(A)).dot(A.T.dot(b))\n",
      "    except np.linalg.LinAlgError:\n",
      "        return None\n",
      "    return H\n",
      "\n",
      "def warpImage(im, H):\n",
      "    transform_matrix = np.array([[H[0], H[1], H[2]],\n",
      "                                 [H[3], H[4], H[5]],\n",
      "                                 [H[6], H[7],    1]])\n",
      "    # Map the four corners of the image into new coordinates, and get all points\n",
      "    start_indices = np.array([[0, 0, 1], [im.shape[1] - 1, 0, 1],\n",
      "                              [im.shape[1] - 1, im.shape[0] - 1, 1], [0, im.shape[0] - 1, 1]])\n",
      "    new_corner_indices = transform_matrix.dot(start_indices.T)\n",
      "    warped_indices = np.apply_along_axis(lambda x: x[:2] / x[2], 0, new_corner_indices)\n",
      "    warped_indices = warped_indices.astype(int)\n",
      "    min_x, max_x = np.min(warped_indices[0]), np.max(warped_indices[0])\n",
      "    min_y, max_y = np.min(warped_indices[1]), np.max(warped_indices[1])\n",
      "    warped_indices[0] += max(0, -min_x)\n",
      "    warped_indices[1] += max(0, -min_y)\n",
      "    \n",
      "    # Create an image buffer after re-aligning the coordinates\n",
      "    img_buffer = np.zeros((max_y - min(0, min_y), max_x - min(0, min_x), 3))\n",
      "    rr, cc = polygon(warped_indices[1], warped_indices[0], img_buffer.shape)\n",
      "    img_buffer[rr, cc, :] = 1\n",
      "    skio.imshow(img_buffer)\n",
      "    skio.show()\n",
      "    img_buffer[rr, cc, :] = 0\n",
      "    cc -= max(0, -min_x)\n",
      "    rr -= max(0, -min_y)\n",
      "    \n",
      "    # Find the corresponding inverse indices on the original image\n",
      "    indices_to_warp = np.vstack((cc, rr, np.ones(cc.shape[0])))\n",
      "    inverse_transform = np.linalg.inv(transform_matrix)\n",
      "    original_indices = inverse_transform.dot(indices_to_warp)\n",
      "    original_indices = np.apply_along_axis(lambda x: x[:2] / x[2], 0, original_indices)\n",
      "    cc += max(0, -min_x)\n",
      "    rr += max(0, -min_y)\n",
      "    \n",
      "    # Run interpolation on the mapped coordinates and copy into image buffer\n",
      "    # Interpolate different colors separately\n",
      "    interp_2d = RectBivariateSpline(np.arange(0, im.shape[0]), np.arange(0, im.shape[1]), im[:, :, 0])\n",
      "    interpolated_pts = interp_2d(original_indices[1], original_indices[0], grid=False)\n",
      "    img_buffer[rr, cc, 0] = interpolated_pts\n",
      "    interp_2d = RectBivariateSpline(np.arange(0, im.shape[0]), np.arange(0, im.shape[1]), im[:, :, 1])\n",
      "    interpolated_pts = interp_2d(original_indices[1], original_indices[0], grid=False)\n",
      "    img_buffer[rr, cc, 1] = interpolated_pts\n",
      "    interp_2d = RectBivariateSpline(np.arange(0, im.shape[0]), np.arange(0, im.shape[1]), im[:, :, 2])\n",
      "    interpolated_pts = interp_2d(original_indices[1], original_indices[0], grid=False)\n",
      "    img_buffer[rr, cc, 2] = interpolated_pts\n",
      "    \n",
      "    # Get the warped center point coordinates\n",
      "    center_x = (max_x - min(0, min_x)) / 2\n",
      "    center_y = (max_y - min(0, min_y)) / 2\n",
      "    \n",
      "    # Return the warped image and x/y coordinate offset values\n",
      "    return img_buffer, max(0, -min_x), max(0, -min_y), center_x, center_y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 519
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read in macbook image and try to get the keyboard view\n",
      "macbook = skio.imread('images/macbook.jpg')\n",
      "macbook = imresize(macbook, 0.2)\n",
      "start_pts = get_points(macbook)\n",
      "end_pts = get_points(macbook)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "H = computeH(start_pts, end_pts)\n",
      "print(H)\n",
      "warped_img = warpImage(macbook, H)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  5.11773283e+01   6.92035285e+01  -2.34743029e+04  -7.87788180e-01\n",
        "   1.28736413e+02  -2.60638620e+04  -1.78018026e-03   1.50638882e-01]\n",
        "[[  0   0   1]\n",
        " [831   0   1]\n",
        " [831 623   1]\n",
        " [  0 623   1]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[   0 5856 3553 3126]\n",
        " [ 840    0 4629 4628]]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skio.imshow(warped_img[0] / 255.)\n",
      "skio.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read in palazzo image and try to get the floor view\n",
      "palazzo = skio.imread('images/palazzo.jpg')\n",
      "start_pts = get_points(palazzo)\n",
      "end_pts = get_points(palazzo)\n",
      "H = computeH(start_pts, end_pts)\n",
      "print(H)\n",
      "warped_img = warpImage(palazzo, H)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  1.11231959e-01  -5.18453465e-01   4.14163842e+02  -4.77499939e-02\n",
        "  -3.55756573e-01   4.02787914e+02  -6.97665809e-05  -1.07013295e-03]\n",
        "[[   0    0    1]\n",
        " [1039    0    1]\n",
        " [1039  779    1]\n",
        " [   0  779    1]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[ 414  571 1340   61]\n",
        " [ 402  380  809  755]]\n"
       ]
      }
     ],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skio.imshow(warped_img[0] / 255.)\n",
      "skio.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_mosaic(source_images, automatic=False):\n",
      "    # Create all mosaics relative to some center image\n",
      "    center_idx = len(source_images) / 2\n",
      "    center_img = source_images[center_idx]\n",
      "    center_img = skimage.img_as_float(center_img)\n",
      "    curr_center_x = center_img.shape[1] / 2\n",
      "    curr_center_y = center_img.shape[0] / 2\n",
      "    \n",
      "    # Blend all images moving towards the left\n",
      "    for i in range(center_idx):\n",
      "        curr_img = source_images[i]\n",
      "        # Show the user both images then ask to select points\n",
      "        skio.imshow(center_img)\n",
      "        skio.show()\n",
      "        skio.imshow(curr_img)\n",
      "        skio.show()\n",
      "        # ginput is quite buggy, the first call doesn't actually register properly\n",
      "        # Only start selecting points on the second call\n",
      "        if automatic:\n",
      "            feature_mapping = generate_feature_match(rgb2gray(curr_img), rgb2gray(center_img))\n",
      "            H = compute_H_ransac(rgb2gray(curr_img), rgb2gray(center_img), feature_mapping)\n",
      "        else:\n",
      "            center_pts = get_points(center_img)\n",
      "            left_pts = get_points(curr_img)\n",
      "            center_pts = get_points(center_img)\n",
      "            H = computeH(left_pts, center_pts)\n",
      "        print(H)\n",
      "        warped_left_img, x_offset, y_offset, warped_x, warped_y = warpImage(curr_img, H)\n",
      "        print(x_offset, y_offset)\n",
      "        warped_left_img /= 255.\n",
      "        # For now, show the result\n",
      "        skio.imshow(warped_left_img)\n",
      "        skio.show()\n",
      "        max_x = max(warped_left_img.shape[1], center_img.shape[1] + x_offset)\n",
      "        max_y = max(warped_left_img.shape[0], center_img.shape[0] + y_offset)\n",
      "        img_buffer = np.zeros((max_y, max_x, 3))\n",
      "        img1_buffer = np.zeros((max_y, max_x, 3))\n",
      "        img2_buffer = np.zeros((max_y, max_x, 3))\n",
      "        img1_buffer[:warped_left_img.shape[0], :warped_left_img.shape[1], :] = warped_left_img[:, :, :]\n",
      "        img2_buffer[y_offset:y_offset + center_img.shape[0],\n",
      "                    x_offset:x_offset + center_img.shape[1], :] = center_img[:, :, :]\n",
      "        img_buffer = linear_blend(img1_buffer, (warped_x, warped_y),\n",
      "                                  img2_buffer, (curr_center_x + x_offset, curr_center_y + y_offset))\n",
      "        skio.imshow(img_buffer)\n",
      "        skio.show()\n",
      "        center_img = img_buffer\n",
      "        curr_center_x = warped_x\n",
      "        curr_center_y = warped_y\n",
      "    \n",
      "    curr_center_x = center_img.shape[1] / 2\n",
      "    curr_center_y = center_img.shape[0] / 2\n",
      "    # Blend all images moving towards the right\n",
      "    for i in range(center_idx + 1, len(source_images)):\n",
      "        curr_img = source_images[i]\n",
      "        # Show the user both images then ask to select points\n",
      "        skio.imshow(center_img)\n",
      "        skio.show()\n",
      "        skio.imshow(curr_img)\n",
      "        skio.show()\n",
      "        # ginput is quite buggy, the first call doesn't actually register properly\n",
      "        # Only start selecting points on the second call\n",
      "        if automatic:\n",
      "            feature_mapping = generate_feature_match(rgb2gray(curr_img), rgb2gray(center_img))\n",
      "            H = compute_H_ransac(rgb2gray(curr_img), rgb2gray(center_img), feature_mapping)\n",
      "        else:\n",
      "            center_pts = get_points(center_img)\n",
      "            center_pts = get_points(center_img)\n",
      "            right_pts = get_points(curr_img)\n",
      "            H = computeH(right_pts, center_pts)\n",
      "        warped_right_img, x_offset, y_offset, warped_x, warped_y = warpImage(curr_img, H)\n",
      "        print(x_offset, y_offset)\n",
      "        warped_right_img /= 255.\n",
      "        # For now, show the result\n",
      "        skio.imshow(warped_right_img)\n",
      "        skio.show()\n",
      "        max_x = max(warped_right_img.shape[1], center_img.shape[1] + x_offset)\n",
      "        max_y = max(warped_right_img.shape[0], center_img.shape[0] + y_offset)\n",
      "        img_buffer = np.zeros((max_y, max_x, 3))\n",
      "        img1_buffer = np.zeros((max_y, max_x, 3))\n",
      "        img2_buffer = np.zeros((max_y, max_x, 3))\n",
      "        img1_buffer[:warped_right_img.shape[0],\n",
      "                    :warped_right_img.shape[1], :] = warped_right_img[:, :, :]\n",
      "        img2_buffer[y_offset:y_offset + center_img.shape[0],\n",
      "                    x_offset:x_offset + center_img.shape[1], :] = center_img[:, :, :]\n",
      "        img_buffer = linear_blend(img1_buffer, (warped_x, warped_y),\n",
      "                                  img2_buffer, (x_offset + curr_center_x, y_offset + curr_center_y))\n",
      "        skio.imshow(img_buffer)\n",
      "        skio.show()\n",
      "        center_img = img_buffer\n",
      "        curr_center_x = warped_x\n",
      "        curr_center_y = warped_y\n",
      "    return center_img\n",
      "\n",
      "\n",
      "# Linear blending code, assume images are the same size\n",
      "def linear_blend(img1, center1, img2, center2):\n",
      "    # Establish areas of overlap, locations to use linear combination of colors\n",
      "    img1_mask = np.zeros(img1.shape[:2])\n",
      "    img2_mask = np.zeros(img2.shape[:2])\n",
      "    img1_mask[np.where(np.sum(img1, axis=2) > 0)] = 1\n",
      "    img2_mask[np.where(np.sum(img2, axis=2) > 0)] = 1\n",
      "    overlap_mask = img1_mask * img2_mask\n",
      "    print(overlap_mask.shape)\n",
      "    \n",
      "    # Make linear gradient with respect to horizontal deviation from center\n",
      "    xv, yv = np.meshgrid(np.arange(img1.shape[1]), np.arange(img2.shape[0]))\n",
      "    # img1_gradient = np.vectorize(\n",
      "    #     lambda x: 1 - 2*(abs(x-center1[0]))/float(img1.shape[1]))(xv)\n",
      "    # img2_gradient = np.vectorize(\n",
      "    #     lambda x: 1 - 2*(abs(x-center2[0]))/float(img2.shape[1]))(xv)\n",
      "    img1_gradient = np.vectorize(\n",
      "        lambda x, y: 1 - 2*(abs(x-center1[0]) + abs(y-center1[1]))/float(img1.shape[1] + img1.shape[0]))(xv, yv)\n",
      "    img2_gradient = np.vectorize(\n",
      "        lambda x, y: 1 - 2*(abs(x-center2[0]) + abs(y-center2[1]))/float(img2.shape[1] + img2.shape[0]))(xv, yv)\n",
      "    skio.imshow(img1_gradient)\n",
      "    skio.show()\n",
      "    skio.imshow(img2_gradient)\n",
      "    skio.show()\n",
      "    total_gradient = img1_gradient + img2_gradient\n",
      "    total_gradient[np.where(total_gradient == 0)] = 1\n",
      "    \n",
      "    # Compute overlapping and non-overlapping regions separately\n",
      "    img_buffer = np.zeros(img1.shape)\n",
      "    img1_indices = np.where(img1_mask == 1)\n",
      "    img2_indices = np.where(img2_mask == 1)\n",
      "    overlap_indices = np.where(overlap_mask == 1)\n",
      "    \n",
      "    img_buffer[img1_indices] = img1[img1_indices]\n",
      "    img_buffer[img2_indices] = img2[img2_indices]\n",
      "    # Handle the three color channels separately\n",
      "    for color_channel in range(3):\n",
      "        curr_indices = overlap_indices + (color_channel,)\n",
      "        print(img_buffer.shape, curr_indices[0].shape)\n",
      "        img_buffer[curr_indices] = img1[curr_indices]\n",
      "        img_buffer[curr_indices] = img2[curr_indices]\n",
      "        img_buffer[curr_indices] = img1[curr_indices]*img1_gradient[overlap_indices] + \\\n",
      "                                   img2[curr_indices]*img2_gradient[overlap_indices]\n",
      "        img_buffer[curr_indices] /= total_gradient[overlap_indices]\n",
      "     \n",
      "    return img_buffer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 444
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read Golden Gate images and perform some warps\n",
      "source_images = []\n",
      "source_images.append(skio.imread('images/golden_gate_left.jpg'))\n",
      "source_images.append(skio.imread('images/golden_gate_center.jpg'))\n",
      "# source_images.append(skio.imread('images/golden_gate_right.jpg'))\n",
      "warped_image = create_mosaic(source_images, automatic=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(4, [0, 1, 2, 4], 7)\n",
        "([(383, 409), (544, 223), (421, 338), (434, 330)], [(86, 256), (116, 156), (22, 234), (34, 228)])\n",
        "[  5.60581810e-02   3.90630463e-02  -3.55744005e+01  -3.31038628e-01\n",
        "  -2.82836521e-01   2.48042388e+02  -1.29880187e-03  -1.17551018e-03]\n",
        "(64, 0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(780, 1104)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-426-7ea6aa65bc4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msource_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/golden_gate_center.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# source_images.append(skio.imread('images/golden_gate_right.jpg'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mwarped_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_mosaic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautomatic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-414-ae594cfafecd>\u001b[0m in \u001b[0;36mcreate_mosaic\u001b[0;34m(source_images, automatic)\u001b[0m\n\u001b[1;32m     41\u001b[0m                     x_offset:x_offset + center_img.shape[1], :] = center_img[:, :, :]\n\u001b[1;32m     42\u001b[0m         img_buffer = linear_blend(img1_buffer, (warped_x, warped_y),\n\u001b[0;32m---> 43\u001b[0;31m                                   img2_buffer, (curr_center_x + x_offset, curr_center_y + y_offset))\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mskio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mskio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-414-ae594cfafecd>\u001b[0m in \u001b[0;36mlinear_blend\u001b[0;34m(img1, center1, img2, center2)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m#     lambda x: 1 - 2*(abs(x-center2[0]))/float(img2.shape[1]))(xv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     img1_gradient = np.vectorize(\n\u001b[0;32m--> 112\u001b[0;31m         lambda x, y: 1 - 2*(abs(x-center1[0]) + abs(y-center1[1]))/float(img1.shape[1] + img1.shape[0]))(xv, yv)\n\u001b[0m\u001b[1;32m    113\u001b[0m     img2_gradient = np.vectorize(\n\u001b[1;32m    114\u001b[0m         lambda x, y: 1 - 2*(abs(x-center2[0]) + abs(y-center2[1]))/float(img2.shape[1] + img2.shape[0]))(xv, yv)\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1698\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36m_vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   1767\u001b[0m                       for _a in args]\n\u001b[1;32m   1768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1769\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-414-ae594cfafecd>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m#     lambda x: 1 - 2*(abs(x-center2[0]))/float(img2.shape[1]))(xv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     img1_gradient = np.vectorize(\n\u001b[0;32m--> 112\u001b[0;31m         lambda x, y: 1 - 2*(abs(x-center1[0]) + abs(y-center1[1]))/float(img1.shape[1] + img1.shape[0]))(xv, yv)\n\u001b[0m\u001b[1;32m    113\u001b[0m     img2_gradient = np.vectorize(\n\u001b[1;32m    114\u001b[0m         lambda x, y: 1 - 2*(abs(x-center2[0]) + abs(y-center2[1]))/float(img2.shape[1] + img2.shape[0]))(xv, yv)\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 426
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skio.imsave('images/golden_gate_linear_blend.jpg', warped_image)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Blend some airplane photos\n",
      "source_images = []\n",
      "# source_images.append(skio.imread('images/plane_left.jpg'))\n",
      "source_images.append(skio.imread('images/plane_center.jpg'))\n",
      "source_images.append(skio.imread('images/plane_right.jpg'))\n",
      "warped_image = create_mosaic(source_images, automatic=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(12, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], 13)\n",
        "([(825, 355), (854, 643), (799, 496), (877, 515), (860, 759), (960, 602), (931, 681), (894, 337), (732, 579), (778, 506), (665, 542), (894, 548)], [(430, 341), (473, 605), (415, 475), (484, 487), (486, 708), (556, 556), (538, 628), (488, 326), (359, 560), (397, 486), (289, 532), (500, 515)])\n",
        "[  1.97982010e+00   1.45394020e-01  -9.19325856e+02   3.12590641e-01\n",
        "   1.69175692e+00  -2.49190758e+02   9.20650415e-04   6.49164028e-05]\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-448-48d893d5a17c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msource_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/plane_center.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msource_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/plane_right.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mwarped_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_mosaic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautomatic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-444-ae594cfafecd>\u001b[0m in \u001b[0;36mcreate_mosaic\u001b[0;34m(source_images, automatic)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_pts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter_pts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mwarped_left_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarped_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarped_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarpImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mwarped_left_img\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-224-9f3b589fa7fb>\u001b[0m in \u001b[0;36mwarpImage\u001b[0;34m(im, H)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0minverse_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0moriginal_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_warp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0moriginal_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mcc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmin_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mrr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmin_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/numpy/lib/shape_base.pyc\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0moutarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutarr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 448
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skio.imsave('images/plane_automatic.jpg', warped_image)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 416
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skio.imsave('images/boston_automatic.jpg', warped_image)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 418
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "source_images = []\n",
      "source_images.append(skio.imread('images/boston_left.jpg'))\n",
      "source_images.append(skio.imread('images/boston_center.jpg'))\n",
      "source_images.append(skio.imread('images/boston_right.jpg'))\n",
      "warped_image = create_mosaic(source_images, automatic=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(8, [3, 4, 5, 7, 8, 9, 11, 12], 13)\n",
        "([(916, 611), (889, 505), (665, 486), (793, 511), (735, 466), (810, 373), (909, 738), (802, 456)], [(482, 599), (466, 503), (255, 487), (381, 510), (329, 465), (404, 378), (470, 713), (392, 457)])\n",
        "[  2.00943864e+00  -8.31194835e-02  -8.73058661e+02   4.62678799e-01\n",
        "   1.73187481e+00  -3.44474493e+02   9.59214800e-04   3.62814503e-05]\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-447-567de57976a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msource_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/boston_center.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msource_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/boston_right.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mwarped_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_mosaic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautomatic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-444-ae594cfafecd>\u001b[0m in \u001b[0;36mcreate_mosaic\u001b[0;34m(source_images, automatic)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_pts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter_pts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mwarped_left_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarped_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarped_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarpImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mwarped_left_img\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-224-9f3b589fa7fb>\u001b[0m in \u001b[0;36mwarpImage\u001b[0;34m(im, H)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0minverse_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0moriginal_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_warp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0moriginal_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mcc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmin_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mrr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmin_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/numpy/lib/shape_base.pyc\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mn\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0moutarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-224-9f3b589fa7fb>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0minverse_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0moriginal_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_warp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0moriginal_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mcc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmin_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mrr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmin_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 447
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "source_images = []\n",
      "source_images.append(skio.imread('images/mit_left.jpg'))\n",
      "source_images.append(skio.imread('images/mit_center.jpg'))\n",
      "source_images.append(skio.imread('images/mit_right.jpg'))\n",
      "warped_image = create_mosaic(source_images, automatic=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(15, [0, 1, 2, 3, 5, 6, 7, 8, 9, 11, 13, 14, 15, 17, 18], 22)\n",
        "([(742, 432), (668, 344), (420, 417), (649, 559), (326, 465), (448, 437), (679, 435), (681, 459), (572, 346), (678, 385), (558, 603), (366, 318), (275, 224), (666, 322), (306, 312)], [(543, 391), (478, 301), (213, 362), (449, 512), (104, 410), (245, 385), (485, 392), (485, 414), (383, 298), (486, 342), (354, 556), (155, 251), (47, 137), (478, 279), (84, 239)])\n",
        "[  1.43641493e+00  -2.86985148e-02  -3.35074527e+02   1.95955440e-01\n",
        "   1.30424005e+00  -1.92771837e+02   3.80715844e-04   8.75110510e-05]\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-446-77d2357391b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msource_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/mit_center.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msource_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/mit_right.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mwarped_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_mosaic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautomatic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-444-ae594cfafecd>\u001b[0m in \u001b[0;36mcreate_mosaic\u001b[0;34m(source_images, automatic)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_pts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter_pts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mwarped_left_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarped_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarped_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarpImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mwarped_left_img\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-224-9f3b589fa7fb>\u001b[0m in \u001b[0;36mwarpImage\u001b[0;34m(im, H)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0minverse_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0moriginal_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_warp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0moriginal_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mcc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmin_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mrr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmin_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Python/2.7/site-packages/numpy/lib/shape_base.pyc\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0moutarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutarr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 446
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Part Two"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_harris_corners(im, edge_discard=20):\n",
      "    \"\"\"\n",
      "    This function takes a b&w image and an optional amount to discard\n",
      "    on the edge (default is 5 pixels), and finds all harris corners\n",
      "    in the image. Harris corners near the edge are discarded and the\n",
      "    coordinates of the remaining corners are returned. A 2d array (h)\n",
      "    containing the h value of every pixel is also returned.\n",
      "\n",
      "    h is the same shape as the original image, im.\n",
      "    coords is 2 x n (ys, xs).\n",
      "    \"\"\"\n",
      "\n",
      "    assert edge_discard >= 20\n",
      "\n",
      "\n",
      "    # find harris corners\n",
      "    h = corner_harris(im, method='eps', sigma=1)\n",
      "    coords = peak_local_max(h, min_distance=1, indices=True)\n",
      "\n",
      "    # discard points on edge\n",
      "    edge = edge_discard  # pixels\n",
      "    mask = (coords[:, 0] > edge) & \\\n",
      "           (coords[:, 0] < im.shape[0] - edge) & \\\n",
      "           (coords[:, 1] > edge) & \\\n",
      "           (coords[:, 1] < im.shape[1] - edge)\n",
      "    coords = coords[mask].T\n",
      "    return h, coords\n",
      "\n",
      "\n",
      "def dist2(x, c):\n",
      "    \"\"\"\n",
      "    dist2  Calculates squared distance between two sets of points.\n",
      "\n",
      "    Description\n",
      "    D = DIST2(X, C) takes two matrices of vectors and calculates the\n",
      "    squared Euclidean distance between them.  Both matrices must be of\n",
      "    the same column dimension.  If X has M rows and N columns, and C has\n",
      "    L rows and N columns, then the result has M rows and L columns.  The\n",
      "    I, Jth entry is the  squared distance from the Ith row of X to the\n",
      "    Jth row of C.\n",
      "\n",
      "    Adapted from code by Christopher M Bishop and Ian T Nabney.\n",
      "    \"\"\"\n",
      "\n",
      "    ndata, dimx = x.shape\n",
      "    ncenters, dimc = c.shape\n",
      "    assert(dimx == dimc), 'Data dimension does not match dimension of centers'\n",
      "\n",
      "    return (np.ones((ncenters, 1)) * np.sum((x**2).T, axis=0)).T + \\\n",
      "            np.ones((   ndata, 1)) * np.sum((c**2).T, axis=0)    - \\\n",
      "            2 * np.inner(x, c)\n",
      "        \n",
      "def harris_adaptive_nonmaximal_suppression(im, edge_discard, num_points):\n",
      "    h, coords = get_harris_corners(im, edge_discard)\n",
      "    # For each point, find the smallest radius such that they are maximum\n",
      "    point_distances = dict()\n",
      "    distance_fn = lambda x, y: sqrt((x[0] - y[0])**2 + (x[1] - y[1])**2)\n",
      "    for i in range(coords.shape[1]):\n",
      "        src_point = (coords[0][i], coords[1][i])\n",
      "        src_intensity = h[src_point]\n",
      "        min_radius = float('inf')\n",
      "        for j in range(coords.shape[1]):\n",
      "            target_point = (coords[0][j], coords[1][j])\n",
      "            target_intensity = h[target_point]\n",
      "            if target_intensity > src_intensity:\n",
      "                curr_radius = distance_fn(src_point, target_point)\n",
      "                if curr_radius < min_radius:\n",
      "                    min_radius = curr_radius\n",
      "        point_distances[src_point] = min_radius\n",
      "    # Sort points in decreasing order of radius, and keep the top N\n",
      "    sorted_points = sorted(point_distances.items(), key=lambda x: -x[1])\n",
      "    top_x, top_y = list(), list()\n",
      "    for i in range(min(num_points, coords.shape[1])):\n",
      "        curr_point, radius = sorted_points[i]\n",
      "        top_y.append(curr_point[0])\n",
      "        top_x.append(curr_point[1])\n",
      "    return h, np.array((np.array(top_y), np.array(top_x)))\n",
      "\n",
      "def extract_feature_points(img, coords):\n",
      "    feature_dict = dict()\n",
      "    # Extract 8x8 feature descriptors at each of the input coordinates\n",
      "    for i in range(coords.shape[1]):\n",
      "        y, x = coords[0][i], coords[1][i]\n",
      "        feature_point = img[y-19:y+21, x-19:x+21]\n",
      "        # Blur and subsample\n",
      "        feature_dict[(y, x)] = imresize(feature_point, (8, 8))\n",
      "    return feature_dict\n",
      "\n",
      "def feature_matching(src_features, target_features):\n",
      "    # For each feature in src, find the top two closest matches in target\n",
      "    # using SSD distance metric\n",
      "    ssd_distance = lambda x, y: np.sum(np.square(x - y))\n",
      "    feature_matches = dict()\n",
      "    for src_coords, src_patch in src_features:\n",
      "        nearest_neighbors = PriorityQueue()\n",
      "        for target_coords, target_patch in target_features:\n",
      "            distance = ssd_distance(target_patch, src_patch)\n",
      "            nearest_neighbors.put((-distance, (target_coords, target_patch)))\n",
      "            if nearest_neighbors.qsize() > 2:\n",
      "                nearest_neighbors.get()\n",
      "        neighbor_list = []\n",
      "        while nearest_neighbors.qsize() > 0:\n",
      "            neighbor_list.append(nearest_neighbors.get()[1])\n",
      "        second_nn, first_nn = neighbor_list\n",
      "        if (ssd_distance(src_patch, first_nn[1]) / float(ssd_distance(src_patch, second_nn[1]))) < 0.8:\n",
      "            feature_matches[src_coords] = neighbor_list\n",
      "    return feature_matches\n",
      "\n",
      "def compute_H_ransac(src_img, target_img, feature_matches):\n",
      "    # Repeatedly select random points from the source image, compute homographies\n",
      "    # and check matching points, for outlier detection\n",
      "    src_points = feature_matches.keys()\n",
      "    curr_y = [point[0] for point in src_points]\n",
      "    curr_x = [point[1] for point in src_points]\n",
      "    points_to_warp = np.array([curr_y, curr_x, [1]*len(src_points)])\n",
      "    curr_y = [feature_matches[point][1][0][0] for point in src_points]\n",
      "    curr_x = [feature_matches[point][1][0][1] for point in src_points]\n",
      "    destination_points = np.array([curr_y, curr_x, [1]*len(src_points)])\n",
      "    max_number_matching = float('-inf')\n",
      "    matching_indices = []\n",
      "    for _ in range(1000):\n",
      "        im1_pts, im2_pts = list(), list()\n",
      "        curr_indices = np.random.choice(len(src_points), 4, replace=False)\n",
      "        for index in curr_indices:\n",
      "            src_point = src_points[index]\n",
      "            target_point = feature_matches[src_point][1][0]\n",
      "            im1_pts.append(src_point)\n",
      "            im2_pts.append(target_point)\n",
      "        H = computeH(im1_pts, im2_pts)\n",
      "        transform_matrix = np.array([[H[0], H[1], H[2]],\n",
      "                                     [H[3], H[4], H[5]],\n",
      "                                     [H[6], H[7],    1]])\n",
      "        transformed_points = transform_matrix.dot(points_to_warp)\n",
      "        transformed_points = np.apply_along_axis(lambda x: x[:2] / x[2], 0, transformed_points)\n",
      "        # Check the indices for number of matching points, record the indices\n",
      "        possible_indices = list()\n",
      "        number_matching = 0\n",
      "        for i in range(transformed_points.shape[1]):\n",
      "            target_point = destination_points[:, i]\n",
      "            transformed_point = transformed_points[:, i]\n",
      "            if sqrt((target_point[0] - transformed_point[0])**2 + \\\n",
      "                    (target_point[1] - transformed_point[1])**2) < 2:\n",
      "                possible_indices.append(i)\n",
      "                number_matching += 1\n",
      "        if number_matching > max_number_matching:\n",
      "            matching_indices = possible_indices\n",
      "            max_number_matching = number_matching\n",
      "        \n",
      "    print(max_number_matching, matching_indices, len(src_points))\n",
      "    im1_pts, im2_pts = list(), list()\n",
      "    for index in matching_indices:\n",
      "        src_point = src_points[index]\n",
      "        target_point = feature_matches[src_point][1][0]\n",
      "        im1_pts.append((src_point[1], src_point[0]))\n",
      "        im2_pts.append((target_point[1], target_point[0]))\n",
      "    print(im1_pts, im2_pts)\n",
      "    return computeH(im1_pts, im2_pts)\n",
      "\n",
      "def generate_feature_match(src_image, target_image):\n",
      "    src_h, src_coords = harris_adaptive_nonmaximal_suppression(src_image, 20, 200)\n",
      "    target_h, target_coords = harris_adaptive_nonmaximal_suppression(target_image, 20, 200)\n",
      "    src_feature_points = extract_feature_points(src_image, src_coords)\n",
      "    target_feature_points = extract_feature_points(target_image, target_coords)\n",
      "    feature_dict = feature_matching(src_feature_points.items(), target_feature_points.items())\n",
      "    \"\"\"\n",
      "    img_buffer = np.zeros((src_image.shape[0], src_image.shape[1] * 2))\n",
      "    img_buffer[:, :src_image.shape[1]] = src_image\n",
      "    img_buffer[:, src_image.shape[1]:] = target_image\n",
      "    plt.imshow(img_buffer, cmap=plt.gray())\n",
      "    for src_point in feature_dict:\n",
      "        target_point = feature_dict[src_point][1][0]\n",
      "        plt.scatter(src_point[1], src_point[0], c='b')\n",
      "        plt.scatter(target_point[1] + src_image.shape[1], target_point[0], c='b')\n",
      "        plt.plot([src_point[1], target_point[1] + src_image.shape[1]], [src_point[0], target_point[0]], 'b')\n",
      "    plt.show()\n",
      "    \"\"\"\n",
      "    return feature_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 502
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "golden_gate = skio.imread('images/boston_left.jpg')\n",
      "golden_gate = rgb2gray(golden_gate)\n",
      "h, coords = harris_adaptive_nonmaximal_suppression(golden_gate, 20, 100)\n",
      "plt.imshow(golden_gate, cmap=plt.get_cmap('gray'))\n",
      "for i in range(coords.shape[1]):\n",
      "    plt.scatter(coords[1][i], coords[0][i], c='b')\n",
      "# plt.savefig('images/golden_gate_harris_suppress.jpg')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 302
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coords"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 287,
       "text": [
        "array([[656, 229, 725, 336, 483, 405, 496, 391, 365, 507, 482, 752, 703,\n",
        "        378, 359, 330, 485, 622, 675, 421, 534, 644, 483, 543, 402, 633,\n",
        "        695, 491, 429, 409, 271, 400, 643, 332, 740, 314, 402, 285, 375,\n",
        "        348, 346, 617, 407, 718, 367, 422, 265, 425, 692, 396, 443, 333,\n",
        "        413, 314, 412, 299, 717, 365, 288, 373, 652, 386, 354, 713, 312,\n",
        "        662, 501, 385, 509, 274, 627, 385, 628, 357, 407, 516, 332, 646,\n",
        "        426, 223, 247, 233, 427, 364, 425, 641, 269, 385, 355, 428, 728,\n",
        "        284, 382, 732, 340, 748, 288, 756, 618, 633],\n",
        "       [525, 524,  32,  83, 744, 368, 508, 655, 510, 377, 273, 362, 299,\n",
        "        243, 172, 434, 198, 331,  61, 530, 258, 462, 148, 202,  95, 416,\n",
        "        497, 104, 215, 410, 521, 327, 566, 531,  62, 404, 441, 445, 364,\n",
        "        351, 409, 498, 160, 480,  44, 346, 469, 131, 540, 301, 516,  58,\n",
        "        184, 511, 508, 426, 518, 533, 535, 105, 405, 528,  94, 538, 535,\n",
        "        453, 267, 278,  97, 502, 471, 346, 541, 335, 392, 124, 512, 388,\n",
        "        152, 544, 515, 504, 329, 380, 403, 445, 538, 511, 395, 373, 467,\n",
        "        489, 227, 496, 365, 495, 513, 471, 419, 523]])"
       ]
      }
     ],
     "prompt_number": 287
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_points = extract_feature_points(golden_gate, coords)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 303
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "golden_gate_right = skio.imread('images/boston_center.jpg')\n",
      "golden_gate_right = rgb2gray(golden_gate_right)\n",
      "h, coords_right = harris_adaptive_nonmaximal_suppression(golden_gate_right, 20, 100)\n",
      "right_features = extract_feature_points(golden_gate_right, coords_right)\n",
      "feature_dict = feature_matching(feature_points.items(), right_features.items())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 307
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skio.imshow(feature_points[(412, 742)])\n",
      "skio.show()\n",
      "skio.imshow(feature_dict[(412, 742)][1][1])\n",
      "skio.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 313
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compute_H_ransac(golden_gate, golden_gate_right, feature_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(12, [0, 1, 2, 5, 6, 7, 8, 10, 14, 15, 17, 18], 19)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 347,
       "text": [
        "array([  1.01283952e+00,   2.00448041e-01,  -2.11641698e+01,\n",
        "        -2.54920543e-01,   1.20777768e+00,  -1.89310442e+02,\n",
        "        -2.00327436e-04,   2.87426068e-04])"
       ]
      }
     ],
     "prompt_number": 347
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skio.imshow(feature_points[(351, 403)])\n",
      "skio.show()\n",
      "skio.imshow(feature_dict[(351, 403)][1][1])\n",
      "skio.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "(351, 403)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-272-b463835c5cdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mskio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_points\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m351\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m403\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mskio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mskio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m351\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m403\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mskio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyError\u001b[0m: (351, 403)"
       ]
      }
     ],
     "prompt_number": 272
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(golden_gate, cmap=plt.get_cmap('gray'))\n",
      "for i in range(coords.shape[1]):\n",
      "    plt.scatter(coords[1][i], coords[0][i], c='b')\n",
      "# plt.savefig('images/golden_gate_harris_suppress.jpg')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 311
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(golden_gate_right, cmap=plt.get_cmap('gray'))\n",
      "for i in range(coords_right.shape[1]):\n",
      "    plt.scatter(coords_right[1][i], coords_right[0][i], c='b')\n",
      "# plt.savefig('images/golden_gate_harris_suppress.jpg')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 312
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(h)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 299
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 448
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Bells and Whistles: Texture Mapping\n",
      "def texture_map(image, background):\n",
      "    skio.imshow(image)\n",
      "    skio.show()\n",
      "    print(background)\n",
      "    skio.imshow(background)\n",
      "    skio.show()\n",
      "    image_pts = [(0, 0), (0, image.shape[0]), (image.shape[1], image.shape[0]), (image.shape[1], 0)]\n",
      "    background_pts = get_points(background)\n",
      "    background_pts = get_points(background)\n",
      "    H = computeH(image_pts, background_pts)\n",
      "    warped_img, x_offset, y_offset, warped_x, warped_y = warpImage(image, H)\n",
      "    indices = np.where(warped_img > 0)\n",
      "    background[indices] = warped_img[indices]\n",
      "    skio.imshow(background)\n",
      "    skio.show()\n",
      "    return background"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 470
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "drake = skio.imread('images/drake_1.jpg')\n",
      "background = skio.imread('images/times_square.jpg')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 471
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "drake = skio.imread('images/drake_11.jpeg')\n",
      "background = texture_map(drake, background)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[[  3   3   3]\n",
        "  [  3   3   3]\n",
        "  [  3   3   3]\n",
        "  ..., \n",
        "  [  3   3   3]\n",
        "  [  3   3   3]\n",
        "  [  3   3   3]]\n",
        "\n",
        " [[  3   3   3]\n",
        "  [  3   3   3]\n",
        "  [  3   3   3]\n",
        "  ..., \n",
        "  [  3   3   3]\n",
        "  [  3   3   3]\n",
        "  [  3   3   3]]\n",
        "\n",
        " [[  3   3   3]\n",
        "  [  3   3   3]\n",
        "  [  3   3   3]\n",
        "  ..., \n",
        "  [  3   3   3]\n",
        "  [  3   3   3]\n",
        "  [  3   3   3]]\n",
        "\n",
        " ..., \n",
        " [[  3   3   3]\n",
        "  [  3   3   3]\n",
        "  [  3   3   3]\n",
        "  ..., \n",
        "  [254 255 255]\n",
        "  [255 254 255]\n",
        "  [255 255 255]]\n",
        "\n",
        " [[  3   3   3]\n",
        "  [  3   3   3]\n",
        "  [  3   3   3]\n",
        "  ..., \n",
        "  [243 219 245]\n",
        "  [245 216 247]\n",
        "  [244 193 236]]\n",
        "\n",
        " [[  3   3   3]\n",
        "  [  3   3   3]\n",
        "  [  3   3   3]\n",
        "  ..., \n",
        "  [174  81 172]\n",
        "  [174  66 167]\n",
        "  [162  34 145]]]\n"
       ]
      }
     ],
     "prompt_number": 487
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "skio.imsave('images/drake_times_square.jpg', background)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 488
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Bells and Whistles: Automatic Panorama Detection\n",
      "def detect_panoramas(list_of_images):\n",
      "    # Extract feature descriptors for each image\n",
      "    list_of_features = []\n",
      "    for img in list_of_images:\n",
      "        src_h, src_coords = harris_adaptive_nonmaximal_suppression(rgb2gray(img), 20, 200)\n",
      "        src_feature_points = extract_feature_points(img, src_coords)\n",
      "        list_of_features.append(src_feature_points)\n",
      "    \n",
      "    panorama_results = []\n",
      "    # Compute pairwise matchings and use Bayes' Rule to decide\n",
      "    for i in range(len(list_of_images)):\n",
      "        src_feature_points = list_of_features[i]\n",
      "        print(i)\n",
      "        for j in range(i + 1, len(list_of_images)):\n",
      "            target_feature_points = list_of_features[j]\n",
      "            feature_matches = feature_matching(src_feature_points.items(), target_feature_points.items())\n",
      "            number_matching, matching_indices = \\\n",
      "                compute_ransac(list_of_images[i], list_of_images[j], feature_matches)\n",
      "            print(number_matching, len(feature_matches))\n",
      "            if number_matching > 5.9 + 0.22*len(feature_matches):\n",
      "                print(\"Found a match!\")\n",
      "                merged_image = create_mosaic([list_of_images[i], list_of_images[j]], automatic=True)\n",
      "                panorama_results.append(merged_image)\n",
      "                break\n",
      "        panorama_results.append(list_of_images[i])\n",
      "    return panorama_results\n",
      "            \n",
      "def compute_ransac(src_img, target_img, feature_matches):\n",
      "    # Repeatedly select random points from the source image, compute homographies\n",
      "    # and check matching points, for outlier detection\n",
      "    src_points = feature_matches.keys()\n",
      "    curr_y = [point[0] for point in src_points]\n",
      "    curr_x = [point[1] for point in src_points]\n",
      "    points_to_warp = np.array([curr_y, curr_x, [1]*len(src_points)])\n",
      "    curr_y = [feature_matches[point][1][0][0] for point in src_points]\n",
      "    curr_x = [feature_matches[point][1][0][1] for point in src_points]\n",
      "    destination_points = np.array([curr_y, curr_x, [1]*len(src_points)])\n",
      "    max_number_matching = float('-inf')\n",
      "    matching_indices = []\n",
      "    if len(src_points) < 4:\n",
      "        return 0, []\n",
      "    \n",
      "    for _ in range(1000):\n",
      "        im1_pts, im2_pts = list(), list()\n",
      "        curr_indices = np.random.choice(len(src_points), 4, replace=False)\n",
      "        for index in curr_indices:\n",
      "            src_point = src_points[index]\n",
      "            target_point = feature_matches[src_point][1][0]\n",
      "            im1_pts.append(src_point)\n",
      "            im2_pts.append(target_point)\n",
      "        H = computeH(im1_pts, im2_pts)\n",
      "        if H is None:\n",
      "            return 0, []\n",
      "        transform_matrix = np.array([[H[0], H[1], H[2]],\n",
      "                                     [H[3], H[4], H[5]],\n",
      "                                     [H[6], H[7],    1]])\n",
      "        transformed_points = transform_matrix.dot(points_to_warp)\n",
      "        transformed_points = np.apply_along_axis(lambda x: x[:2] / x[2], 0, transformed_points)\n",
      "        # Check the indices for number of matching points, record the indices\n",
      "        possible_indices = list()\n",
      "        number_matching = 0\n",
      "        for i in range(transformed_points.shape[1]):\n",
      "            target_point = destination_points[:, i]\n",
      "            transformed_point = transformed_points[:, i]\n",
      "            if sqrt((target_point[0] - transformed_point[0])**2 + \\\n",
      "                    (target_point[1] - transformed_point[1])**2) < 2:\n",
      "                possible_indices.append(i)\n",
      "                number_matching += 1\n",
      "        if number_matching > max_number_matching:\n",
      "            matching_indices = possible_indices\n",
      "            max_number_matching = number_matching\n",
      "    return max_number_matching, matching_indices"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 528
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list_of_images = []\n",
      "list_of_images.append(skio.imread('images/plane_center.jpg'))\n",
      "list_of_images.append(skio.imread('images/mit_center.jpg'))\n",
      "list_of_images.append(skio.imread('images/boston_left.jpg'))\n",
      "list_of_images.append(skio.imread('images/plane_right.jpg'))\n",
      "list_of_images.append(skio.imread('images/golden_gate_left.jpg'))\n",
      "list_of_images.append(skio.imread('images/boston_center.jpg'))\n",
      "results = detect_panoramas(list_of_images)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "(0, 0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0, 0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(31, 41)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found a match!\n",
        "(12, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], 13)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "([(825, 355), (854, 643), (799, 496), (877, 515), (860, 759), (960, 602), (931, 681), (894, 337), (732, 579), (778, 506), (665, 542), (894, 548)], [(430, 341), (473, 605), (415, 475), (484, 487), (486, 708), (556, 556), (538, 628), (488, 326), (359, 560), (397, 486), (289, 532), (500, 515)])\n",
        "[  1.97982010e+00   1.45394020e-01  -9.19325856e+02   3.12590641e-01\n",
        "   1.69175692e+00  -2.49190758e+02   9.20650415e-04   6.49164028e-05]\n",
        "(919, 249)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(1266, 1959)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "((1266, 1959, 3), (451334,))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "((1266, 1959, 3), (451334,))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "((1266, 1959, 3), (451334,))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0, 0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0, 0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0, 3)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0, 0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2\n",
        "(0, 2)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0, 0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(34, 61)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found a match!\n",
        "(19, [1, 4, 6, 10, 11, 14, 17, 18, 21, 22, 23, 24, 26, 27, 29, 31, 32, 34, 35], 37)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "([(694, 451), (583, 327), (652, 381), (634, 359), (518, 550), (417, 552), (730, 550), (666, 352), (762, 294), (742, 412), (368, 573), (395, 540), (909, 417), (779, 465), (971, 399), (438, 339), (730, 298), (895, 406), (489, 441)], [(479, 518), (381, 387), (446, 446), (430, 423), (285, 617), (170, 615), (503, 620), (462, 419), (555, 371), (527, 483), (110, 638), (146, 601), (677, 497), (559, 536), (730, 485), (224, 385), (526, 372), (665, 486), (268, 498)])\n",
        "[  1.30940440e+00  -1.85284671e-01  -2.62614937e+02   2.43037778e-01\n",
        "   1.09746937e+00  -5.37616165e+01   3.53278274e-04  -1.54886195e-04]\n",
        "(462, 53)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(964, 1502)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "((964, 1502, 3), (558540,))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "((964, 1502, 3), (558540,))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "((964, 1502, 3), (558540,))"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0, 19)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(0, 0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4\n",
        "(0, 1)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5\n"
       ]
      }
     ],
     "prompt_number": 529
    }
   ],
   "metadata": {}
  }
 ]
}